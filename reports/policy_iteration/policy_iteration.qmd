---
work:
    type: 'Лабораторная работа'
    theme: 'Обучение с подкреплением. Алгоритм Policy Iteration'
    number: '1'
---

{{< include ../title-page.qmd >}}
## Задание
На основе рассмотренного на лекции примера реализуйте алгоритм Policy Iteration для любой среды обучения с подкреплением (кроме рассмотренной на лекции среды Toy Text / Frozen Lake) из библиотеки Gym (или аналогичной библиотеки).

## Выполнение
Исходный код программы:
```python
{{< include ../../src/policy_iteration/main.py >}}
```

И содержимое `toy_environment.consts`:
```python
{{< include ../../src/toy_environment/consts.py >}}
```

## Результат
Одна тысяча итераций:

![](../execution_results/policy_iteration/play_captures/PolicyIteration_1_000.mp4)

Сто тысяч итераций:

![](../execution_results/policy_iteration/play_captures/PolicyIteration_100_000.mp4)

## Вывод
В этой лабораторной работе мы реализовали алгоритм Policy Iteration.
Этот алгоритм отлично справился с задачей Frozen Lake и Taxi.

Однако совершенно не справился с задачей Cliff Walking, вероятнее всего дело в
особенности наград в данном сценарии: Policy Iteration редко получает обратную
реакцию от среды, лишь постоянно уходит в минус из-за превышения количества
ходов и падения в обрыв.

